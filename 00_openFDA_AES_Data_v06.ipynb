{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de25f363-65b0-4450-bd10-e1e266e7a729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alberto Bejarano (2025)\n",
    "# 00_openFDA_AES_Data_v06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb1a6e8e-81de-405e-bddb-60cc8e3a22aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script is designed to retrieve and process adverse event data from the FDA API for specified drugs. It operates\n",
    "# in a modular manner, encapsulating functionality within distinct functions to enhance clarity and maintainability.\n",
    "# Initially, the script loads an API key from a JSON file, which is used to authenticate and manage request limits\n",
    "# with the FDA API. Next, it reads drug aliases from an Excel file to ensure consistent naming of drugs, accounting\n",
    "# for multiple synonyms.\n",
    "# For each drug specified in the drugs_of_interest list, the script fetches adverse event data in batches, handling\n",
    "# potential errors such as rate limits using an exponential backoff strategy. The data is requested from the FDA API,\n",
    "# focusing on serious adverse event categories like death, hospitalization, and life-threatening conditions.\n",
    "# The fetched data is organized into a pandas DataFrame, which facilitates further data manipulation and analysis.\n",
    "# Finally, the processed data for each drug is saved into individual CSV files, named dynamically to reflect the drug\n",
    "# being analyzed. This ensures clear data organization and prevents overwriting of files. Throughout, the script\n",
    "# employs logging and warnings for diagnostic purposes, helping users track the progress and identify any issues\n",
    "# encountered during API interaction and data processing. The modular design makes it straightforward to adapt for\n",
    "# other datasets or extend functionality based on evolving data requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6feb023c-b963-41f6-9d16-c20a7d70a14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "class RequestWarning(UserWarning):   pass\n",
    "class RetryWarning(UserWarning):     pass\n",
    "class DrugFetchWarning(UserWarning): pass\n",
    "class DataEndWarning(UserWarning):   pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1efc90c-09e2-406b-b7d8-50b202a0f693",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE     = 100                      # Number of records per batch during API requests\n",
    "TOTAL_RECORDS  = 50000                    # Total number of records to fetch for each drug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "776abed5-50bb-4536-99ed-212f0ce5b15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, requests, time, os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from tqdm import tqdm # Ensure tqdm is imported for progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bca71ff-7dd0-45eb-b60b-84527497ff46",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_FDA_URL     = \"https://api.fda.gov/drug/event.json\"\n",
    "JSON_FILE_PATH  = \"./data/fda_api_key.json\"\n",
    "DRUG_DICT_FILE  = \"./data/Drug_Dictionary.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fed083-0567-4992-9afb-6da41cf8fed3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0fda96a-4662-459c-a207-57d76065bcde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Standards Of Care\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nStandards Of Care\")\n",
    "INPUT_DRUG_LIST_FILE = './data/StandardsOfCare.txt'\n",
    "AES_OUTPUT_FILE      = './data/AdverseEvents/AES_StandardsOfCare'\n",
    "#         .        .         .         .        .         .         .        .         .         .        .         .         .        .         .\n",
    "#print(f\"\\nDrugs Of Interest\")\n",
    "#INPUT_DRUG_LIST_FILE = './data2/DrugsofInterest.txt'\n",
    "#AES_OUTPUT_FILE      = './data2/AdverseEvents/AES_DrugsofInterest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea6b2f03-6446-4432-8f7d-b1066ba66e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_api_key(json_file_path):          # Load API key from a JSON file\n",
    "    with open(json_file_path, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "        api_key = data.get('api_key')\n",
    "        print(\"API key loaded.\")          # Confirmation message\n",
    "        return api_key                    # Return the loaded API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2e58bf0-1b22-4223-8606-40b0d499a649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_file_exists(file_path):           # Check if a file exists.\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"Required file {file_path} not found.\")\n",
    "    print(f\"File {file_path} exists.\")    # Confirmation message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c29824f-1e0d-4e8b-b129-217acc616bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_safe_request(BASE_URL, params, api_key=None, retries=3, initial_delay=1, backoff=2):\n",
    "    \"\"\" Send API request to FDA with error handling and exponential backoff for managing rate limits. \"\"\"\n",
    "    delay = initial_delay                # Set initial delay for backoff strategy\n",
    "    if api_key:\n",
    "        params['api_key'] = api_key      # Include API key in request parameters if available\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            response = requests.get(API_FDA_URL, params=params, timeout=30) # Send a GET request\n",
    "            if response.status_code == 200:     # Successful request\n",
    "                return response                 # Return successful response\n",
    "            elif response.status_code == 429:   # Rate limit exceeded, retry with delay\n",
    "                warnings.warn(\"Rate limit exceeded. Retrying...\")\n",
    "                time.sleep(delay * (backoff ** i))\n",
    "            elif response.status_code in [400, 404]:   # Bad request or not found\n",
    "                warnings.warn(f\"Request failed with status {response.status_code}: {response.reason}\")\n",
    "                break\n",
    "        except requests.exceptions.ReadTimeout:         # Handle request timeout\n",
    "            warnings.warn(\"Read timeout occurred. Retrying...\")\n",
    "            time.sleep(delay * (backoff ** i))\n",
    "        except requests.exceptions.RequestException as e:  # Handle other request exceptions\n",
    "            warnings.warn(f\"Request failed due to: {e}\")\n",
    "            break\n",
    "    warnings.warn(\"All retries failed.\")               # Warn if all retries fail\n",
    "    return None                                         # Return None if request fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0073d82b-f933-4bfe-bc1a-acb2bd9d1d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_drug_aliases(drug_dict_file):\n",
    "    \"\"\" Retrieve drug aliases from an Excel file and organize them into a dictionary. \"\"\"\n",
    "    dictionary_df = pd.read_csv(drug_dict_file, sep='\\t')         # Load CSV file into a DataFrame\n",
    "    alias_dict = {}                                     # Initialize dictionary for aliases\n",
    "    for _, row in dictionary_df.iterrows():             # Iterate over each row in the DataFrame\n",
    "        drug_name = row['Drug_Name'].strip().replace('\\xa0', '').lower() # Get primary drug name, cleaned and formatted\n",
    "        alias_dict[drug_name] = drug_name               # Map primary name to itself\n",
    "        if pd.notna(row['Other_Drug_Names']):           # Check for any aliases\n",
    "            aliases = [name.strip().replace('\\xa0', '').lower() for name in row['Other_Drug_Names'].split(',')]\n",
    "            for alias in aliases:\n",
    "                alias_dict[alias] = drug_name           # Map each alias to the primary name\n",
    "    return alias_dict                                   # Return the dictionary of aliases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbaa0156-df0d-4a1f-9224-d82e48cbbefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_adverse_events(drug_name, api_key, alias_dict):\n",
    "    \"\"\" Fetch adverse event data for the drug and return a DataFrame. \"\"\"\n",
    "    all_records = []                                     # List to store all fetched records\n",
    "\n",
    "    # Request metadata to estimate total number of records for current drug\n",
    "    meta_params = {\"search\": f\"patient.drug.medicinalproduct:{drug_name}\", \"api_key\": api_key, \"limit\": 1}\n",
    "    meta_response = send_safe_request(API_FDA_URL, meta_params)                         # Make metadata request\n",
    "    if not meta_response:                                                          # Handle failed metadata fetch\n",
    "        warnings.warn(f\"Metadata request failed for '{drug_name}'. Skipping.\")\n",
    "        return pd.DataFrame()\n",
    "    try:\n",
    "        TOTAL_RECORDS = meta_response.json()[\"meta\"][\"results\"][\"total\"]           # Extract total number of records\n",
    "    except (KeyError, TypeError) as e:                                              # Handle parsing issues\n",
    "        warnings.warn(f\"Metadata parsing failed for '{drug_name}': {e}. Skipping.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    for skip in tqdm(range(0, TOTAL_RECORDS, BATCH_SIZE), desc=f\"Fetching {drug_name} AES\", unit=\"batch\"):\n",
    "        # Set parameter for search query including medicinal product name, batch size, and skip count for pagination\n",
    "        params = {\"search\": f\"patient.drug.medicinalproduct:{drug_name}\", \"limit\": BATCH_SIZE, \"skip\": skip}\n",
    "        response = send_safe_request(API_FDA_URL, params, api_key) # Fetch data with proper request handling\n",
    "#         .        .         .         .        .         .         .        .         .         .        .         .         .        .         .\n",
    "        if not response:                                 # Handle failed response\n",
    "            warnings.warn(f\"Failed to fetch data for {drug_name}. Skipping.\")\n",
    "            break\n",
    "#         .        .         .         .        .         .         .        .         .         .        .         .         .        .         .\n",
    "        data = response.json(); results = data.get(\"results\", [])             # Parse JSON response for results\n",
    "#         .        .         .         .        .         .         .        .         .         .        .         .         .        .         .\n",
    "        if not results:                                                       # No results returned\n",
    "            warnings.warn(f\"No data returned for batch {skip}.\")\n",
    "            break\n",
    "#         .        .         .         .        .         .         .        .         .         .        .         .         .        .         .\n",
    "        # Process each result, adding seriousness data to records list\n",
    "        for result in results:\n",
    "            seriousness = {\n",
    "                \"Death\": int(result.get(\"seriousnessdeath\",                     0)),\n",
    "                \"Hospitalization\": int(result.get(\"seriousnesshospitalization\", 0)),\n",
    "                \"LifeThreatening\": int(result.get(\"seriousnesslifethreatening\", 0)),\n",
    "                \"Other\": int(result.get(\"seriousnessother\",                     0))}\n",
    "            \n",
    "            for reaction in result.get(\"patient\", {}).get(\"reaction\", []):                               # Retrieve and format reaction data\n",
    "                record = {\"Drug_Name\": alias_dict.get(drug_name.lower(), drug_name),\n",
    "                          \"Adverse_Event\": reaction.get(\"reactionmeddrapt\", \"Unknown\"), **seriousness}    # Include seriousness information             \n",
    "                all_records.append(record)                              # Append the processed record to all records\n",
    "#         .        .         .         .        .         .         .        .         .         .        .         .         .        .         .\n",
    "        # End of results indicated by fewer than expected batch size\n",
    "        if len(results) < BATCH_SIZE:\n",
    "            warnings.warn(f\"Reached the end of data for {drug_name}.\")\n",
    "            break\n",
    "\n",
    "    return pd.DataFrame(all_records)                                    # Convert accumulated records to a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "189c3cb1-c5a4-4c9f-acff-0cf82854e8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data_to_csv(df, drug_name):\n",
    "    \"\"\" Save the DataFrame to a CSV file. \"\"\"\n",
    "    if not df.empty:                                                    # Ensure DataFrame has data\n",
    "        columns_to_format = ['%Death', '%Hospitalization', '%LifeThreatening', '%Other', '%Total']\n",
    "        decimals = 2                                                    # Set decimal precision\n",
    "        # Format decimal places of specific columns\n",
    "        for column in columns_to_format:\n",
    "            if column in df.columns:\n",
    "                df[column] = df[column].apply(lambda x: round(x, decimals))\n",
    "\n",
    "        filename = f\"{AES_OUTPUT_FILE}_{drug_name}.csv\"                # Define filename for output\n",
    "        df.to_csv(filename, index=False)                               # Save DataFrame to CSV file\n",
    "        print(f\"Data saved to {filename}\")                             # Confirmation message\n",
    "    else:\n",
    "        print(f\"No data available for {drug_name}.\")                   # Notify if there is no data to save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5e10c23-3488-4e20-abdf-a23a9c5b3d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Check if essential input files exist to prevent runtime errors\n",
    "    check_file_exists(JSON_FILE_PATH)\n",
    "    check_file_exists(DRUG_DICT_FILE)\n",
    "#         .        .         .         .        .         .         .        .         .         .        .         .         .        .         .\n",
    "    # Load API key and drug aliases for data retrieval\n",
    "    api_key    = load_api_key(JSON_FILE_PATH)\n",
    "    alias_dict = get_drug_aliases(DRUG_DICT_FILE)\n",
    "#         .        .         .         .        .         .         .        .         .         .        .         .         .        .         .\n",
    "    # Load drugs of interest from the specified text file for processing\n",
    "    with open(INPUT_DRUG_LIST_FILE, 'r') as file:\n",
    "        drugs_of_interest = [line.strip() for line in file.readlines()]\n",
    "#         .        .         .         .        .         .         .        .         .         .        .         .         .        .         .\n",
    "    # Process each drug independently\n",
    "    for drug_name in drugs_of_interest:\n",
    "        # Sanitize drug name for file name usage to eliminate problematic characters\n",
    "        safe_drug_name = drug_name.replace(\" \", \"_\").replace(\"/\", \"_\").lower()\n",
    "#         .        .         .         .        .         .         .        .         .         .        .         .         .        .         .\n",
    "        # Construct the filename using the sanitized drug name\n",
    "        CSV_FILENAME = f\"{AES_OUTPUT_FILE}_{safe_drug_name}.csv\"\n",
    "        print(f\"\\nCheck if file exists: {CSV_FILENAME}\")\n",
    "        if os.path.exists(CSV_FILENAME):                          # Check if output file already exists\n",
    "            print(f\"CSV file for {drug_name} already exists. Skipping..\")\n",
    "            continue\n",
    "        print(f\"Processing adverse events for {drug_name}...\")\n",
    "#         .        .         .         .        .         .         .        .         .         .        .         .         .        .         .\n",
    "        # Fetch data for both the original name and all aliases by iterating over alias list\n",
    "        all_events_df = pd.DataFrame()\n",
    "        for alias in [name for name, original in alias_dict.items() if original == drug_name.lower()]:\n",
    "            temp_df = fetch_adverse_events(alias, api_key, alias_dict)\n",
    "            all_events_df = pd.concat([all_events_df, temp_df], ignore_index=True) # Concatenate data for all aliases\n",
    "#         .        .         .         .        .         .         .        .         .         .        .         .         .        .         .\n",
    "        # If data is present, group and sort adverse events, save top 100 events\n",
    "        if not all_events_df.empty:\n",
    "            # Grouping by Drug and Event, summing numerical columns to aggregate seriousness\n",
    "            grouped_events = all_events_df.groupby(['Drug_Name', 'Adverse_Event']).sum().reset_index()\n",
    "            # Create a new column for total severity\n",
    "            grouped_events['Total_Severity'] = grouped_events['Death']+grouped_events['Hospitalization']+ \\\n",
    "                                               grouped_events['LifeThreatening']+grouped_events['Other']\n",
    "#         .        .         .         .        .         .         .        .         .         .        .         .         .        .         .\n",
    "            TXT_FILENAME = f\"{AES_OUTPUT_FILE}_{safe_drug_name}.txt\"\n",
    "            adverse_event_list = all_events_df['Adverse_Event'].unique().tolist()\n",
    "            with open(TXT_FILENAME, 'w', encoding='utf-8') as f:\n",
    "                for event in adverse_event_list:\n",
    "                    f.write(f\"{event}\\n\")\n",
    "                print(f\"Data saved to {TXT_FILENAME}\") \n",
    "#         .        .         .         .        .         .         .        .         .         .        .         .         .        .         .            \n",
    "            sorted_events = grouped_events.sort_values(by='Total_Severity', ascending=False).head(100)\n",
    "            save_data_to_csv(sorted_events, drug_name)                  # Save top events to CSV\n",
    "        else:\n",
    "            print(f\"No data available for {drug_name}.\")                # Inform no data is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e511108-56e2-4d08-9803-6967184217b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ./data/fda_api_key.json exists.\n",
      "File ./data/Drug_Dictionary.csv exists.\n",
      "API key loaded.\n",
      "\n",
      "Check if file exists: ./data/AdverseEvents/AES_StandardsOfCare_fluorouracil.csv\n",
      "CSV file for Fluorouracil already exists. Skipping..\n",
      "\n",
      "Check if file exists: ./data/AdverseEvents/AES_StandardsOfCare_tamoxifen.csv\n",
      "CSV file for Tamoxifen already exists. Skipping..\n",
      "\n",
      "Check if file exists: ./data/AdverseEvents/AES_StandardsOfCare_letrozole.csv\n",
      "CSV file for Letrozole already exists. Skipping..\n",
      "\n",
      "Check if file exists: ./data/AdverseEvents/AES_StandardsOfCare_anastrozole.csv\n",
      "CSV file for Anastrozole already exists. Skipping..\n",
      "\n",
      "Check if file exists: ./data/AdverseEvents/AES_StandardsOfCare_exemestane.csv\n",
      "CSV file for Exemestane already exists. Skipping..\n",
      "\n",
      "Check if file exists: ./data/AdverseEvents/AES_StandardsOfCare_palbociclib.csv\n",
      "Processing adverse events for Palbociclib...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching palbociclib AES:  99%|█████████▉| 102/103 [03:11<00:01,  1.94s/batch]C:\\Users\\alber\\AppData\\Local\\Temp\\ipykernel_12244\\2416140407.py:47: UserWarning: Reached the end of data for palbociclib.\n",
      "  warnings.warn(f\"Reached the end of data for {drug_name}.\")\n",
      "Fetching palbociclib AES:  99%|█████████▉| 102/103 [03:13<00:01,  1.89s/batch]\n",
      "Fetching ibrance AES:  31%|███       | 251/804 [06:55<14:16,  1.55s/batch]C:\\Users\\alber\\AppData\\Local\\Temp\\ipykernel_12244\\593540702.py:15: UserWarning: Request failed with status 400: Bad Request\n",
      "  warnings.warn(f\"Request failed with status {response.status_code}: {response.reason}\")\n",
      "C:\\Users\\alber\\AppData\\Local\\Temp\\ipykernel_12244\\593540702.py:23: UserWarning: All retries failed.\n",
      "  warnings.warn(\"All retries failed.\")               # Warn if all retries fail\n",
      "C:\\Users\\alber\\AppData\\Local\\Temp\\ipykernel_12244\\2416140407.py:23: UserWarning: Failed to fetch data for ibrance. Skipping.\n",
      "  warnings.warn(f\"Failed to fetch data for {drug_name}. Skipping.\")\n",
      "Fetching ibrance AES:  31%|███       | 251/804 [06:55<15:16,  1.66s/batch]\n",
      "Fetching pd 0332991 AES:  99%|█████████▉| 146/147 [03:35<00:01,  1.05s/batch]C:\\Users\\alber\\AppData\\Local\\Temp\\ipykernel_12244\\2416140407.py:47: UserWarning: Reached the end of data for pd 0332991.\n",
      "  warnings.warn(f\"Reached the end of data for {drug_name}.\")\n",
      "Fetching pd 0332991 AES:  99%|█████████▉| 146/147 [03:36<00:01,  1.48s/batch]\n",
      "Fetching pd 332991 AES:  99%|█████████▉| 146/147 [03:36<00:01,  1.04s/batch]C:\\Users\\alber\\AppData\\Local\\Temp\\ipykernel_12244\\2416140407.py:47: UserWarning: Reached the end of data for pd 332991.\n",
      "  warnings.warn(f\"Reached the end of data for {drug_name}.\")\n",
      "Fetching pd 332991 AES:  99%|█████████▉| 146/147 [03:37<00:01,  1.49s/batch]\n",
      "Fetching pd-0332991 AES:  37%|███▋      | 54/147 [01:17<02:34,  1.66s/batch]"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    start_time = time.time()                                            # Record start time\n",
    "    main()                                                              # Execute main function\n",
    "    elapsed_time = time.time() - start_time                             # Calculate elapsed time\n",
    "    minutes, seconds = divmod(elapsed_time, 60)                         # Convert elapsed time to minutes and seconds\n",
    "    print(f\"Completed in {int(minutes)} min {int(seconds)} sec.\")       # Print completion message with elapsed time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a649546-0bca-4250-b52a-5d7ed453f28e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
